{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gastos_cartao = pd.read_csv(\"base_gastos_cartao.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gastos_Cartao</th>\n",
       "      <th>Idade</th>\n",
       "      <th>Renda</th>\n",
       "      <th>Impostos</th>\n",
       "      <th>Segmento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510</td>\n",
       "      <td>35</td>\n",
       "      <td>1120</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>490</td>\n",
       "      <td>30</td>\n",
       "      <td>1120</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>470</td>\n",
       "      <td>32</td>\n",
       "      <td>1040</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>460</td>\n",
       "      <td>31</td>\n",
       "      <td>1200</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>36</td>\n",
       "      <td>1120</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>540</td>\n",
       "      <td>39</td>\n",
       "      <td>1360</td>\n",
       "      <td>120</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>460</td>\n",
       "      <td>34</td>\n",
       "      <td>1120</td>\n",
       "      <td>90</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>500</td>\n",
       "      <td>34</td>\n",
       "      <td>1200</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>440</td>\n",
       "      <td>29</td>\n",
       "      <td>1120</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>490</td>\n",
       "      <td>31</td>\n",
       "      <td>1200</td>\n",
       "      <td>30</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>540</td>\n",
       "      <td>37</td>\n",
       "      <td>1200</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>480</td>\n",
       "      <td>34</td>\n",
       "      <td>1280</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>480</td>\n",
       "      <td>30</td>\n",
       "      <td>1120</td>\n",
       "      <td>30</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>430</td>\n",
       "      <td>30</td>\n",
       "      <td>880</td>\n",
       "      <td>30</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>580</td>\n",
       "      <td>40</td>\n",
       "      <td>960</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>570</td>\n",
       "      <td>44</td>\n",
       "      <td>1200</td>\n",
       "      <td>120</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>540</td>\n",
       "      <td>39</td>\n",
       "      <td>1040</td>\n",
       "      <td>120</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>510</td>\n",
       "      <td>35</td>\n",
       "      <td>1120</td>\n",
       "      <td>90</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>570</td>\n",
       "      <td>38</td>\n",
       "      <td>1360</td>\n",
       "      <td>90</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>510</td>\n",
       "      <td>38</td>\n",
       "      <td>1200</td>\n",
       "      <td>90</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>540</td>\n",
       "      <td>34</td>\n",
       "      <td>1360</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>510</td>\n",
       "      <td>37</td>\n",
       "      <td>1200</td>\n",
       "      <td>120</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>460</td>\n",
       "      <td>36</td>\n",
       "      <td>800</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>510</td>\n",
       "      <td>33</td>\n",
       "      <td>1360</td>\n",
       "      <td>150</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>480</td>\n",
       "      <td>34</td>\n",
       "      <td>1520</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>500</td>\n",
       "      <td>30</td>\n",
       "      <td>1280</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>500</td>\n",
       "      <td>34</td>\n",
       "      <td>1280</td>\n",
       "      <td>120</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>520</td>\n",
       "      <td>35</td>\n",
       "      <td>1200</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>520</td>\n",
       "      <td>34</td>\n",
       "      <td>1120</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>470</td>\n",
       "      <td>32</td>\n",
       "      <td>1280</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>690</td>\n",
       "      <td>32</td>\n",
       "      <td>4560</td>\n",
       "      <td>690</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>560</td>\n",
       "      <td>28</td>\n",
       "      <td>3920</td>\n",
       "      <td>600</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>770</td>\n",
       "      <td>28</td>\n",
       "      <td>5360</td>\n",
       "      <td>600</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>630</td>\n",
       "      <td>27</td>\n",
       "      <td>3920</td>\n",
       "      <td>540</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>670</td>\n",
       "      <td>33</td>\n",
       "      <td>4560</td>\n",
       "      <td>630</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>720</td>\n",
       "      <td>32</td>\n",
       "      <td>4800</td>\n",
       "      <td>540</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>620</td>\n",
       "      <td>28</td>\n",
       "      <td>3840</td>\n",
       "      <td>540</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>610</td>\n",
       "      <td>30</td>\n",
       "      <td>3920</td>\n",
       "      <td>540</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>640</td>\n",
       "      <td>28</td>\n",
       "      <td>4480</td>\n",
       "      <td>630</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>720</td>\n",
       "      <td>30</td>\n",
       "      <td>4640</td>\n",
       "      <td>480</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>740</td>\n",
       "      <td>28</td>\n",
       "      <td>4880</td>\n",
       "      <td>570</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>790</td>\n",
       "      <td>38</td>\n",
       "      <td>5120</td>\n",
       "      <td>600</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>640</td>\n",
       "      <td>28</td>\n",
       "      <td>4480</td>\n",
       "      <td>660</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>630</td>\n",
       "      <td>28</td>\n",
       "      <td>4080</td>\n",
       "      <td>450</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>610</td>\n",
       "      <td>26</td>\n",
       "      <td>4480</td>\n",
       "      <td>420</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>770</td>\n",
       "      <td>30</td>\n",
       "      <td>4880</td>\n",
       "      <td>690</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>630</td>\n",
       "      <td>34</td>\n",
       "      <td>4480</td>\n",
       "      <td>720</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>640</td>\n",
       "      <td>31</td>\n",
       "      <td>4400</td>\n",
       "      <td>540</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>600</td>\n",
       "      <td>30</td>\n",
       "      <td>3840</td>\n",
       "      <td>540</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>690</td>\n",
       "      <td>31</td>\n",
       "      <td>4320</td>\n",
       "      <td>630</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>670</td>\n",
       "      <td>31</td>\n",
       "      <td>4480</td>\n",
       "      <td>720</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>690</td>\n",
       "      <td>31</td>\n",
       "      <td>4080</td>\n",
       "      <td>690</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>580</td>\n",
       "      <td>27</td>\n",
       "      <td>4080</td>\n",
       "      <td>570</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>680</td>\n",
       "      <td>32</td>\n",
       "      <td>4720</td>\n",
       "      <td>690</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>670</td>\n",
       "      <td>33</td>\n",
       "      <td>4560</td>\n",
       "      <td>750</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>670</td>\n",
       "      <td>30</td>\n",
       "      <td>4160</td>\n",
       "      <td>690</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>630</td>\n",
       "      <td>25</td>\n",
       "      <td>4000</td>\n",
       "      <td>570</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>650</td>\n",
       "      <td>30</td>\n",
       "      <td>4160</td>\n",
       "      <td>600</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>620</td>\n",
       "      <td>34</td>\n",
       "      <td>4320</td>\n",
       "      <td>690</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>590</td>\n",
       "      <td>30</td>\n",
       "      <td>4080</td>\n",
       "      <td>540</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gastos_Cartao  Idade  Renda  Impostos Segmento\n",
       "0              510     35   1120        60        C\n",
       "1              490     30   1120        60        C\n",
       "2              470     32   1040        60        C\n",
       "3              460     31   1200        60        C\n",
       "4              500     36   1120        60        C\n",
       "5              540     39   1360       120        C\n",
       "6              460     34   1120        90        C\n",
       "7              500     34   1200        60        C\n",
       "8              440     29   1120        60        C\n",
       "9              490     31   1200        30        C\n",
       "10             540     37   1200        60        C\n",
       "11             480     34   1280        60        C\n",
       "12             480     30   1120        30        C\n",
       "13             430     30    880        30        C\n",
       "14             580     40    960        60        C\n",
       "15             570     44   1200       120        C\n",
       "16             540     39   1040       120        C\n",
       "17             510     35   1120        90        C\n",
       "18             570     38   1360        90        C\n",
       "19             510     38   1200        90        C\n",
       "20             540     34   1360        60        C\n",
       "21             510     37   1200       120        C\n",
       "22             460     36    800        60        C\n",
       "23             510     33   1360       150        C\n",
       "24             480     34   1520        60        C\n",
       "25             500     30   1280        60        C\n",
       "26             500     34   1280       120        C\n",
       "27             520     35   1200        60        C\n",
       "28             520     34   1120        60        C\n",
       "29             470     32   1280        60        C\n",
       "..             ...    ...    ...       ...      ...\n",
       "120            690     32   4560       690        A\n",
       "121            560     28   3920       600        A\n",
       "122            770     28   5360       600        A\n",
       "123            630     27   3920       540        A\n",
       "124            670     33   4560       630        A\n",
       "125            720     32   4800       540        A\n",
       "126            620     28   3840       540        A\n",
       "127            610     30   3920       540        A\n",
       "128            640     28   4480       630        A\n",
       "129            720     30   4640       480        A\n",
       "130            740     28   4880       570        A\n",
       "131            790     38   5120       600        A\n",
       "132            640     28   4480       660        A\n",
       "133            630     28   4080       450        A\n",
       "134            610     26   4480       420        A\n",
       "135            770     30   4880       690        A\n",
       "136            630     34   4480       720        A\n",
       "137            640     31   4400       540        A\n",
       "138            600     30   3840       540        A\n",
       "139            690     31   4320       630        A\n",
       "140            670     31   4480       720        A\n",
       "141            690     31   4080       690        A\n",
       "142            580     27   4080       570        A\n",
       "143            680     32   4720       690        A\n",
       "144            670     33   4560       750        A\n",
       "145            670     30   4160       690        A\n",
       "146            630     25   4000       570        A\n",
       "147            650     30   4160       600        A\n",
       "148            620     34   4320       690        A\n",
       "149            590     30   4080       540        A\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gastos_cartao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gastos_cartao.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gastos_Cartao</th>\n",
       "      <th>Idade</th>\n",
       "      <th>Renda</th>\n",
       "      <th>Impostos</th>\n",
       "      <th>Segmento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>510</td>\n",
       "      <td>35</td>\n",
       "      <td>1120</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>490</td>\n",
       "      <td>30</td>\n",
       "      <td>1120</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>470</td>\n",
       "      <td>32</td>\n",
       "      <td>1040</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>460</td>\n",
       "      <td>31</td>\n",
       "      <td>1200</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>36</td>\n",
       "      <td>1120</td>\n",
       "      <td>60</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gastos_Cartao  Idade  Renda  Impostos Segmento\n",
       "0            510     35   1120        60        C\n",
       "1            490     30   1120        60        C\n",
       "2            470     32   1040        60        C\n",
       "3            460     31   1200        60        C\n",
       "4            500     36   1120        60        C"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gastos_cartao.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating matrix of features and target\n",
    "#### Repair the categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([gastos_cartao[['Idade', 'Renda', 'Impostos']], pd.get_dummies(gastos_cartao.Segmento)], axis=1)\n",
    "y = gastos_cartao.Gastos_Cartao\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 6)\n",
      "(45, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import neural network for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import method to put all features in the same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using just the train data to get the parameters to scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplying the scaler for the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply the transformations to the data:\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Neural network model with specific parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(30,30,30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the predictions in the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 20305.6245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE: %.4f\" % mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try to improve the model optimizing the hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the grid of hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'hidden_layer_sizes': [(1,), (5,), (10,), (5,5,)],\n",
    "                     'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                     'learning_rate': ['constant', 'adaptive'],\n",
    "                     'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing all the combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'alpha': [0.0001, 0.001, 0.01, 0.1, 1], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'learning_rate': ['constant', 'adaptive'], 'hidden_layer_sizes': [(1,), (5,), (10,), (5, 5)]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='r2', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(MLPRegressor(), tuned_parameters, cv=3, scoring='r2')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing the performance of all combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "()\n",
      "{'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "-46.295 (+/-4.382) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.449 (+/-4.165) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.561 (+/-4.391) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.421 (+/-4.517) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.352 (+/-4.287) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.365 (+/-4.431) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-45.685 (+/-4.134) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.240 (+/-4.598) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.467 (+/-4.038) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.583 (+/-4.397) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.344 (+/-4.346) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.369 (+/-4.254) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.334 (+/-4.382) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.241 (+/-4.225) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-46.254 (+/-4.298) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-45.877 (+/-4.027) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.626 (+/-4.422) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.680 (+/-3.826) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.301 (+/-4.006) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.472 (+/-4.016) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.132 (+/-4.316) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.190 (+/-4.412) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-46.069 (+/-4.434) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.123 (+/-3.969) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.585 (+/-4.417) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.520 (+/-4.104) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.404 (+/-4.441) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.313 (+/-4.473) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.249 (+/-4.026) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.495 (+/-4.160) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-46.261 (+/-4.450) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-45.791 (+/-4.087) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.497 (+/-4.636) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.558 (+/-3.917) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.446 (+/-4.064) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.396 (+/-3.890) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.327 (+/-4.077) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.273 (+/-4.344) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-45.969 (+/-3.956) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-45.979 (+/-4.347) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.596 (+/-4.177) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.632 (+/-4.178) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.397 (+/-4.197) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.519 (+/-4.248) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.416 (+/-4.185) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.317 (+/-4.233) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-46.459 (+/-4.097) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.512 (+/-4.033) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.502 (+/-4.046) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.395 (+/-4.187) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.484 (+/-4.227) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.446 (+/-4.174) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.361 (+/-4.267) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.370 (+/-4.306) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-46.319 (+/-4.310) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.385 (+/-4.118) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.511 (+/-3.944) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.608 (+/-4.236) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.493 (+/-3.977) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.497 (+/-4.173) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.398 (+/-4.110) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.425 (+/-4.232) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-46.475 (+/-4.156) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.457 (+/-4.400) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.495 (+/-4.159) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.567 (+/-4.051) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.445 (+/-4.130) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.437 (+/-4.046) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.466 (+/-4.175) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.286 (+/-4.217) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-46.494 (+/-4.130) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.521 (+/-4.390) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.539 (+/-4.116) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.451 (+/-4.082) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.416 (+/-4.166) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.499 (+/-4.053) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.467 (+/-4.080) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.415 (+/-4.019) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-46.426 (+/-4.268) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.512 (+/-4.158) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.534 (+/-4.544) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.488 (+/-4.539) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.395 (+/-3.999) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.406 (+/-3.964) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.392 (+/-4.177) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.353 (+/-4.200) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-46.271 (+/-4.121) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.362 (+/-4.197) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.568 (+/-4.106) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.582 (+/-4.200) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.563 (+/-4.139) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.482 (+/-4.106) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.301 (+/-4.001) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.289 (+/-4.059) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-46.221 (+/-4.249) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.431 (+/-4.358) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.503 (+/-3.711) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.293 (+/-4.130) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.386 (+/-3.929) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.496 (+/-4.229) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.314 (+/-4.130) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.352 (+/-4.283) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-46.341 (+/-4.383) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.395 (+/-4.066) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.448 (+/-3.916) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.484 (+/-4.220) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.492 (+/-4.340) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.397 (+/-4.301) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.444 (+/-4.133) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.354 (+/-4.132) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-46.319 (+/-4.116) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.410 (+/-4.263) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.594 (+/-3.709) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.410 (+/-4.016) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.406 (+/-4.385) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.314 (+/-4.050) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.331 (+/-3.999) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.294 (+/-4.220) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-45.989 (+/-4.024) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.286 (+/-4.301) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.632 (+/-4.361) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.529 (+/-3.932) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.229 (+/-3.774) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.471 (+/-3.991) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.089 (+/-3.838) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.286 (+/-4.252) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-46.203 (+/-4.613) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.251 (+/-3.818) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.411 (+/-4.172) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.429 (+/-4.457) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.490 (+/-4.210) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.301 (+/-4.369) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.300 (+/-4.348) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.273 (+/-4.221) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-46.138 (+/-4.862) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.415 (+/-4.027) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.531 (+/-4.026) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.498 (+/-4.160) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.437 (+/-3.916) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.282 (+/-4.064) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.187 (+/-4.271) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.077 (+/-4.190) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-46.260 (+/-3.690) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-45.842 (+/-3.778) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.365 (+/-4.040) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.576 (+/-4.589) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.224 (+/-3.823) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.409 (+/-4.094) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.236 (+/-4.041) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.228 (+/-4.197) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-46.296 (+/-4.179) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.239 (+/-4.652) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.600 (+/-4.034) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "-46.692 (+/-4.308) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "-46.243 (+/-4.388) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "-46.287 (+/-4.165) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "-46.252 (+/-4.043) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "-46.106 (+/-4.386) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "-45.884 (+/-4.301) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "-46.211 (+/-4.481) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "MSE: 330525.1269\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "mse = mean_squared_error(y_test, clf.predict(X_test))\n",
    "print(\"MSE: %.4f\" % mse)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"train_titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = titanic.columns.tolist()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.pop(features.index('Name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cabin'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.pop(features.index('Ticket'))\n",
    "features.pop(features.index('Cabin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = pd.concat([titanic[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']], pd.get_dummies(titanic[['Sex', 'Embarked']])], axis=1)\n",
    "y = titanic.Survived\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass    :    0\n",
      "Age    :    119\n",
      "SibSp    :    0\n",
      "Parch    :    0\n",
      "Fare    :    0\n",
      "Sex_female    :    0\n",
      "Sex_male    :    0\n",
      "Embarked_C    :    0\n",
      "Embarked_Q    :    0\n",
      "Embarked_S    :    0\n"
     ]
    }
   ],
   "source": [
    "for i in features:\n",
    "    print i + '    :    ' + str(sum(X_train[i].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Big\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "mediana = X_train.Age.median()\n",
    "\n",
    "X_train.loc[X_train.Age.isnull(),'Age'] = mediana\n",
    "X_test.loc[X_test.Age.isnull(),'Age'] = mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass    :    0\n",
      "Age    :    0\n",
      "SibSp    :    0\n",
      "Parch    :    0\n",
      "Fare    :    0\n",
      "Sex_female    :    0\n",
      "Sex_male    :    0\n",
      "Embarked_C    :    0\n",
      "Embarked_Q    :    0\n",
      "Embarked_S    :    0\n"
     ]
    }
   ],
   "source": [
    "for i in features:\n",
    "    print i + '    :    ' + str(sum(X_train[i].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass\n",
      "Survived       \n",
      "0         count    397.000000\n",
      "          mean       2.526448\n",
      "          std        0.740209\n",
      "          min        1.000000\n",
      "          25%        2.000000\n",
      "          50%        3.000000\n",
      "          75%        3.000000\n",
      "          max        3.000000\n",
      "1         count    226.000000\n",
      "          mean       1.977876\n",
      "          std        0.856062\n",
      "          min        1.000000\n",
      "          25%        1.000000\n",
      "          50%        2.000000\n",
      "          75%        3.000000\n",
      "          max        3.000000\n",
      "Name: Pclass, dtype: float64\n",
      "Age\n",
      "Survived       \n",
      "0         count    397.000000\n",
      "          mean      29.743073\n",
      "          std       12.487801\n",
      "          min        1.000000\n",
      "          25%       23.000000\n",
      "          50%       28.000000\n",
      "          75%       34.500000\n",
      "          max       74.000000\n",
      "1         count    226.000000\n",
      "          mean      28.233407\n",
      "          std       13.838029\n",
      "          min        0.670000\n",
      "          25%       22.000000\n",
      "          50%       28.000000\n",
      "          75%       35.000000\n",
      "          max       63.000000\n",
      "Name: Age, dtype: float64\n",
      "SibSp\n",
      "Survived       \n",
      "0         count    397.000000\n",
      "          mean       0.576826\n",
      "          std        1.309355\n",
      "          min        0.000000\n",
      "          25%        0.000000\n",
      "          50%        0.000000\n",
      "          75%        1.000000\n",
      "          max        8.000000\n",
      "1         count    226.000000\n",
      "          mean       0.508850\n",
      "          std        0.725664\n",
      "          min        0.000000\n",
      "          25%        0.000000\n",
      "          50%        0.000000\n",
      "          75%        1.000000\n",
      "          max        4.000000\n",
      "Name: SibSp, dtype: float64\n",
      "Parch\n",
      "Survived       \n",
      "0         count    397.000000\n",
      "          mean       0.355164\n",
      "          std        0.862990\n",
      "          min        0.000000\n",
      "          25%        0.000000\n",
      "          50%        0.000000\n",
      "          75%        0.000000\n",
      "          max        6.000000\n",
      "1         count    226.000000\n",
      "          mean       0.477876\n",
      "          std        0.801081\n",
      "          min        0.000000\n",
      "          25%        0.000000\n",
      "          50%        0.000000\n",
      "          75%        1.000000\n",
      "          max        5.000000\n",
      "Name: Parch, dtype: float64\n",
      "Fare\n",
      "Survived       \n",
      "0         count    397.000000\n",
      "          mean      23.047332\n",
      "          std       33.001644\n",
      "          min        0.000000\n",
      "          25%        7.895800\n",
      "          50%       10.500000\n",
      "          75%       26.550000\n",
      "          max      263.000000\n",
      "1         count    226.000000\n",
      "          mean      48.787058\n",
      "          std       71.124533\n",
      "          min        0.000000\n",
      "          25%       12.381250\n",
      "          50%       26.000000\n",
      "          75%       57.734400\n",
      "          max      512.329200\n",
      "Name: Fare, dtype: float64\n",
      "Sex_female\n",
      "Survived       \n",
      "0         count    397.000000\n",
      "          mean       0.148615\n",
      "          std        0.356157\n",
      "          min        0.000000\n",
      "          25%        0.000000\n",
      "          50%        0.000000\n",
      "          75%        0.000000\n",
      "          max        1.000000\n",
      "1         count    226.000000\n",
      "          mean       0.685841\n",
      "          std        0.465211\n",
      "          min        0.000000\n",
      "          25%        0.000000\n",
      "          50%        1.000000\n",
      "          75%        1.000000\n",
      "          max        1.000000\n",
      "Name: Sex_female, dtype: float64\n",
      "Sex_male\n",
      "Survived       \n",
      "0         count    397.000000\n",
      "          mean       0.851385\n",
      "          std        0.356157\n",
      "          min        0.000000\n",
      "          25%        1.000000\n",
      "          50%        1.000000\n",
      "          75%        1.000000\n",
      "          max        1.000000\n",
      "1         count    226.000000\n",
      "          mean       0.314159\n",
      "          std        0.465211\n",
      "          min        0.000000\n",
      "          25%        0.000000\n",
      "          50%        0.000000\n",
      "          75%        1.000000\n",
      "          max        1.000000\n",
      "Name: Sex_male, dtype: float64\n",
      "Embarked_C\n",
      "Survived       \n",
      "0         count    397.000000\n",
      "          mean       0.138539\n",
      "          std        0.345901\n",
      "          min        0.000000\n",
      "          25%        0.000000\n",
      "          50%        0.000000\n",
      "          75%        0.000000\n",
      "          max        1.000000\n",
      "1         count    226.000000\n",
      "          mean       0.256637\n",
      "          std        0.437747\n",
      "          min        0.000000\n",
      "          25%        0.000000\n",
      "          50%        0.000000\n",
      "          75%        1.000000\n",
      "          max        1.000000\n",
      "Name: Embarked_C, dtype: float64\n",
      "Embarked_Q\n",
      "Survived       \n",
      "0         count    397.000000\n",
      "          mean       0.083123\n",
      "          std        0.276417\n",
      "          min        0.000000\n",
      "          25%        0.000000\n",
      "          50%        0.000000\n",
      "          75%        0.000000\n",
      "          max        1.000000\n",
      "1         count    226.000000\n",
      "          mean       0.070796\n",
      "          std        0.257054\n",
      "          min        0.000000\n",
      "          25%        0.000000\n",
      "          50%        0.000000\n",
      "          75%        0.000000\n",
      "          max        1.000000\n",
      "Name: Embarked_Q, dtype: float64\n",
      "Embarked_S\n",
      "Survived       \n",
      "0         count    397.000000\n",
      "          mean       0.778338\n",
      "          std        0.415889\n",
      "          min        0.000000\n",
      "          25%        1.000000\n",
      "          50%        1.000000\n",
      "          75%        1.000000\n",
      "          max        1.000000\n",
      "1         count    226.000000\n",
      "          mean       0.668142\n",
      "          std        0.471926\n",
      "          min        0.000000\n",
      "          25%        0.000000\n",
      "          50%        1.000000\n",
      "          75%        1.000000\n",
      "          max        1.000000\n",
      "Name: Embarked_S, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in features:\n",
    "    print i\n",
    "    print X_train.groupby(y_train)[i].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(623, 10)\n",
      "(268, 10)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now apply the transformations to the data:\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = mlp.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc_ = roc_auc_score(y_test, probs[:,1])\n",
    "print(\"AUC: %.4f\" % auc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia: 0.8097\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"acurácia: %.4f\" % accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[136  16]\n",
      " [ 35  81]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.89      0.84       152\n",
      "          1       0.84      0.70      0.76       116\n",
      "\n",
      "avg / total       0.81      0.81      0.81       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print classification_report(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{'hidden_layer_sizes': [(1,), (5,), (10,), (5,5,)],\n",
    "                     'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                     'learning_rate': ['constant', 'adaptive'],\n",
    "                     'alpha': [0.0001, 0.001, 0.01, 0.1, 1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Big\\Anaconda2\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'alpha': [0.0001, 0.001, 0.01, 0.1, 1], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'learning_rate': ['constant', 'adaptive'], 'hidden_layer_sizes': [(1,), (5,), (10,), (5, 5)]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(MLPClassifier(), tuned_parameters, cv=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "()\n",
      "{'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.657 (+/-0.416) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.767 (+/-0.052) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.795 (+/-0.034) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.790 (+/-0.042) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.801 (+/-0.059) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.798 (+/-0.038) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.796 (+/-0.042) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.798 (+/-0.046) for {'alpha': 0.0001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.777 (+/-0.068) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.713 (+/-0.120) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.793 (+/-0.053) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.787 (+/-0.038) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.795 (+/-0.034) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.796 (+/-0.044) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.793 (+/-0.027) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.796 (+/-0.039) for {'alpha': 0.001, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.754 (+/-0.150) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.791 (+/-0.050) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.790 (+/-0.050) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.788 (+/-0.058) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.799 (+/-0.038) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.793 (+/-0.035) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.777 (+/-0.029) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.798 (+/-0.032) for {'alpha': 0.01, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.764 (+/-0.019) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.788 (+/-0.058) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.796 (+/-0.044) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.795 (+/-0.051) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.798 (+/-0.046) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.793 (+/-0.048) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.782 (+/-0.037) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.796 (+/-0.034) for {'alpha': 0.1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.734 (+/-0.112) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.754 (+/-0.157) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.809 (+/-0.056) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.796 (+/-0.039) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.801 (+/-0.044) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.806 (+/-0.037) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.801 (+/-0.037) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.788 (+/-0.035) for {'alpha': 1, 'activation': 'identity', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.727 (+/-0.131) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.759 (+/-0.073) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.793 (+/-0.036) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.787 (+/-0.008) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.787 (+/-0.044) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.790 (+/-0.048) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.692 (+/-0.155) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.682 (+/-0.125) for {'alpha': 0.0001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.637 (+/-0.001) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.637 (+/-0.001) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.791 (+/-0.031) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.775 (+/-0.040) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.795 (+/-0.041) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.791 (+/-0.037) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.693 (+/-0.157) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.637 (+/-0.001) for {'alpha': 0.001, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.677 (+/-0.114) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.663 (+/-0.071) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.778 (+/-0.026) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.769 (+/-0.062) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.780 (+/-0.028) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.788 (+/-0.047) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.689 (+/-0.097) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.668 (+/-0.087) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.666 (+/-0.083) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.454 (+/-0.259) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.788 (+/-0.022) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.782 (+/-0.049) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.798 (+/-0.032) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.791 (+/-0.050) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.640 (+/-0.010) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.682 (+/-0.067) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.546 (+/-0.259) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.637 (+/-0.001) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.751 (+/-0.055) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.735 (+/-0.068) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.809 (+/-0.031) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.806 (+/-0.038) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.637 (+/-0.001) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.637 (+/-0.001) for {'alpha': 1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.652 (+/-0.410) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.684 (+/-0.075) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.795 (+/-0.034) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.790 (+/-0.043) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.801 (+/-0.034) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.801 (+/-0.044) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.796 (+/-0.046) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.785 (+/-0.049) for {'alpha': 0.0001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.689 (+/-0.143) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.717 (+/-0.126) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.790 (+/-0.068) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.795 (+/-0.028) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.803 (+/-0.050) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.803 (+/-0.050) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.807 (+/-0.042) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.807 (+/-0.038) for {'alpha': 0.001, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.700 (+/-0.127) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.753 (+/-0.033) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.788 (+/-0.047) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.804 (+/-0.035) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.793 (+/-0.040) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.798 (+/-0.032) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.778 (+/-0.020) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.803 (+/-0.038) for {'alpha': 0.01, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.626 (+/-0.304) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.748 (+/-0.097) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.785 (+/-0.057) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.801 (+/-0.044) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.798 (+/-0.046) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.801 (+/-0.039) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.795 (+/-0.034) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.790 (+/-0.035) for {'alpha': 0.1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.782 (+/-0.030) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.501 (+/-0.325) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.793 (+/-0.030) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.790 (+/-0.035) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.791 (+/-0.062) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.803 (+/-0.034) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.807 (+/-0.040) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.803 (+/-0.039) for {'alpha': 1, 'activation': 'tanh', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.624 (+/-0.371) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.644 (+/-0.017) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.806 (+/-0.030) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.799 (+/-0.035) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.799 (+/-0.046) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.809 (+/-0.047) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.758 (+/-0.081) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.811 (+/-0.038) for {'alpha': 0.0001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.693 (+/-0.081) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.596 (+/-0.351) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.693 (+/-0.320) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.796 (+/-0.023) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.801 (+/-0.023) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.806 (+/-0.038) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.790 (+/-0.071) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.762 (+/-0.183) for {'alpha': 0.001, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.602 (+/-0.366) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.756 (+/-0.040) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.809 (+/-0.051) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.790 (+/-0.038) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.809 (+/-0.051) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.812 (+/-0.040) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.785 (+/-0.025) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.790 (+/-0.066) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.737 (+/-0.151) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.637 (+/-0.281) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.807 (+/-0.030) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.783 (+/-0.027) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.811 (+/-0.037) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.803 (+/-0.030) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.820 (+/-0.058) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.785 (+/-0.034) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.586 (+/-0.331) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.517 (+/-0.383) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.803 (+/-0.040) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5,)}\n",
      "0.778 (+/-0.121) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5,)}\n",
      "0.806 (+/-0.057) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.809 (+/-0.069) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.795 (+/-0.034) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.799 (+/-0.042) for {'alpha': 1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.88      0.83       152\n",
      "          1       0.82      0.69      0.75       116\n",
      "\n",
      "avg / total       0.80      0.80      0.80       268\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.91      0.83       152\n",
      "          1       0.84      0.65      0.73       116\n",
      "\n",
      "avg / total       0.80      0.79      0.79       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 500, 'max_depth': 2, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01}\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{'n_estimators': [10, 100, 300],\n",
    "                     'max_depth' : [3, 10],\n",
    "                     'min_samples_split': [2, 10],\n",
    "                     'learning_rate': [0.001, 0.1], \n",
    "                     'subsample': [0.5, 1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [10, 100, 300], 'min_samples_split': [2, 10], 'learning_rate': [0.001, 0.1], 'max_depth': [3, 10], 'subsample': [0.5, 1]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(ensemble.GradientBoostingClassifier(), tuned_parameters, cv=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "()\n",
      "{'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.637 (+/-0.003) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.637 (+/-0.003) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 1}\n",
      "0.637 (+/-0.003) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.637 (+/-0.003) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 1}\n",
      "0.790 (+/-0.056) for {'min_samples_split': 2, 'n_estimators': 300, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.807 (+/-0.046) for {'min_samples_split': 2, 'n_estimators': 300, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 1}\n",
      "0.637 (+/-0.003) for {'min_samples_split': 10, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.637 (+/-0.003) for {'min_samples_split': 10, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 1}\n",
      "0.637 (+/-0.003) for {'min_samples_split': 10, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.637 (+/-0.003) for {'min_samples_split': 10, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 1}\n",
      "0.782 (+/-0.058) for {'min_samples_split': 10, 'n_estimators': 300, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.807 (+/-0.046) for {'min_samples_split': 10, 'n_estimators': 300, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 1}\n",
      "0.637 (+/-0.003) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.637 (+/-0.003) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 1}\n",
      "0.637 (+/-0.003) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.637 (+/-0.003) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 1}\n",
      "0.777 (+/-0.069) for {'min_samples_split': 2, 'n_estimators': 300, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.799 (+/-0.062) for {'min_samples_split': 2, 'n_estimators': 300, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 1}\n",
      "0.637 (+/-0.003) for {'min_samples_split': 10, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.637 (+/-0.003) for {'min_samples_split': 10, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 1}\n",
      "0.637 (+/-0.003) for {'min_samples_split': 10, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.637 (+/-0.003) for {'min_samples_split': 10, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 1}\n",
      "0.767 (+/-0.064) for {'min_samples_split': 10, 'n_estimators': 300, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.791 (+/-0.070) for {'min_samples_split': 10, 'n_estimators': 300, 'learning_rate': 0.001, 'max_depth': 10, 'subsample': 1}\n",
      "0.809 (+/-0.039) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.820 (+/-0.062) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1}\n",
      "0.815 (+/-0.055) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.833 (+/-0.061) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1}\n",
      "0.820 (+/-0.032) for {'min_samples_split': 2, 'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.823 (+/-0.065) for {'min_samples_split': 2, 'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1}\n",
      "0.806 (+/-0.057) for {'min_samples_split': 10, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.820 (+/-0.062) for {'min_samples_split': 10, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1}\n",
      "0.828 (+/-0.056) for {'min_samples_split': 10, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.828 (+/-0.074) for {'min_samples_split': 10, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1}\n",
      "0.815 (+/-0.060) for {'min_samples_split': 10, 'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.822 (+/-0.057) for {'min_samples_split': 10, 'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 1}\n",
      "0.804 (+/-0.039) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.814 (+/-0.066) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 1}\n",
      "0.814 (+/-0.066) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.798 (+/-0.059) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 1}\n",
      "0.796 (+/-0.044) for {'min_samples_split': 2, 'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.791 (+/-0.063) for {'min_samples_split': 2, 'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 1}\n",
      "0.817 (+/-0.047) for {'min_samples_split': 10, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.807 (+/-0.047) for {'min_samples_split': 10, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 1}\n",
      "0.807 (+/-0.043) for {'min_samples_split': 10, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.809 (+/-0.050) for {'min_samples_split': 10, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 1}\n",
      "0.796 (+/-0.055) for {'min_samples_split': 10, 'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 0.5}\n",
      "0.799 (+/-0.043) for {'min_samples_split': 10, 'n_estimators': 300, 'learning_rate': 0.1, 'max_depth': 10, 'subsample': 1}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.88      0.83       152\n",
      "          1       0.82      0.70      0.75       116\n",
      "\n",
      "avg / total       0.80      0.80      0.80       268\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SVC(C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.93      0.85       152\n",
      "          1       0.87      0.66      0.75       116\n",
      "\n",
      "avg / total       0.82      0.81      0.80       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf', 'linear', 'poly'],\n",
    "                     'C': [1, 10, 100, 1000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

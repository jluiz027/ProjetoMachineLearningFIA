{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancer = pd.read_csv(\"cancer.data.txt\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1   2   3   4   5   6   7   8   9   10\n",
       "0  1000025   5   1   1   1   2   1   3   1   1   2\n",
       "1  1002945   5   4   4   5   7  10   3   2   1   2\n",
       "2  1015425   3   1   1   1   2   2   3   1   1   2\n",
       "3  1016277   6   8   8   1   3   4   3   7   1   2\n",
       "4  1017023   4   1   1   3   2   1   3   1   1   2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancer.columns = [\"v0\", \"v1\", \"v2\", \"v3\", \"v4\", \"v5\", \"v6\", \"v7\", \"v8\", \"v9\", \"v10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1     10\n",
       "2      2\n",
       "3      4\n",
       "4      1\n",
       "5     10\n",
       "6     10\n",
       "7      1\n",
       "8      1\n",
       "9      1\n",
       "10     1\n",
       "11     1\n",
       "12     3\n",
       "13     3\n",
       "14     9\n",
       "15     1\n",
       "16     1\n",
       "17     1\n",
       "18    10\n",
       "19     1\n",
       "20    10\n",
       "21     7\n",
       "22     1\n",
       "23     ?\n",
       "24     1\n",
       "25     7\n",
       "26     1\n",
       "27     1\n",
       "28     1\n",
       "29     1\n",
       "30     1\n",
       "31     1\n",
       "32     5\n",
       "33     1\n",
       "34     1\n",
       "35     1\n",
       "36     1\n",
       "37     1\n",
       "38    10\n",
       "39     7\n",
       "40     ?\n",
       "41     3\n",
       "42    10\n",
       "43     1\n",
       "44     1\n",
       "45     1\n",
       "46     9\n",
       "47     1\n",
       "48     1\n",
       "49     8\n",
       "Name: v6, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.v6.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancer.v6 = cancer.v6.replace(\"?\", np.nan).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting Target in 0-1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cancer.v10 = cancer.v10/2-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = cancer[[\"v1\", \"v2\", \"v3\", \"v4\", \"v5\", \"v6\", \"v7\", \"v8\", \"v9\"]]\n",
    "y = cancer.v10\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(489, 9)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 9)\n"
     ]
    }
   ],
   "source": [
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1   :    0\n",
      "v2   :    0\n",
      "v3   :    0\n",
      "v4   :    0\n",
      "v5   :    0\n",
      "v6   :    8\n",
      "v7   :    0\n",
      "v8   :    0\n",
      "v9   :    0\n"
     ]
    }
   ],
   "source": [
    "for i in X.columns:\n",
    "    print i + '   :    ' + str(sum(X_train[i].isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Big\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "mediana = X_train.v6.median()\n",
    "print mediana\n",
    "X_train.loc[X_train.v6.isnull(), 'v6'] = mediana\n",
    "X_test.loc[X_test.v6.isnull(), 'v6'] = mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1   :    0\n",
      "v2   :    0\n",
      "v3   :    0\n",
      "v4   :    0\n",
      "v5   :    0\n",
      "v6   :    0\n",
      "v7   :    0\n",
      "v8   :    0\n",
      "v9   :    0\n"
     ]
    }
   ],
   "source": [
    "for i in X.columns:\n",
    "    print i + '   :    ' + str(sum(X_train[i].isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now apply the transformations to the data:\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Big\\Anaconda2\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 30, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs = mlp.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9870\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "auc_ = roc_auc_score(y_test, probs[:,1])\n",
    "print(\"AUC: %.4f\" % auc_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acurácia: 0.9571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"acurácia: %.4f\" % accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[132   6]\n",
      " [  3  69]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.96      0.97       138\n",
      "        1.0       0.92      0.96      0.94        72\n",
      "\n",
      "avg / total       0.96      0.96      0.96       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print classification_report(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{'hidden_layer_sizes': [(1,), (10,), (5,5,)],\n",
    "                     'activation' : ['logistic', 'relu'],\n",
    "                     'learning_rate': ['constant', 'adaptive'],\n",
    "                     'alpha': [0.01, 0.1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'alpha': [0.01, 0.1], 'activation': ['logistic', 'relu'], 'learning_rate': ['constant', 'adaptive'], 'hidden_layer_sizes': [(1,), (10,), (5, 5)]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(MLPClassifier(), tuned_parameters, cv=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "()\n",
      "{'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.838 (+/-0.188) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.622 (+/-0.426) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.953 (+/-0.020) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.965 (+/-0.029) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.904 (+/-0.119) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.896 (+/-0.061) for {'alpha': 0.01, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.654 (+/-0.003) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.683 (+/-0.078) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.963 (+/-0.030) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.961 (+/-0.025) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.945 (+/-0.017) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.853 (+/-0.285) for {'alpha': 0.1, 'activation': 'logistic', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.759 (+/-0.587) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.851 (+/-0.282) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.969 (+/-0.026) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.961 (+/-0.040) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.961 (+/-0.030) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.965 (+/-0.029) for {'alpha': 0.01, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "0.661 (+/-0.020) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (1,)}\n",
      "0.642 (+/-0.474) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1,)}\n",
      "0.975 (+/-0.026) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (10,)}\n",
      "0.975 (+/-0.010) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (10,)}\n",
      "0.961 (+/-0.035) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'constant', 'hidden_layer_sizes': (5, 5)}\n",
      "0.965 (+/-0.029) for {'alpha': 0.1, 'activation': 'relu', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (5, 5)}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.96      0.97       138\n",
      "        1.0       0.93      0.96      0.95        72\n",
      "\n",
      "avg / total       0.96      0.96      0.96       210\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.97      0.96       138\n",
      "        1.0       0.94      0.89      0.91        72\n",
      "\n",
      "avg / total       0.94      0.94      0.94       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 500, 'max_depth': 2, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01}\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{'n_estimators': [10, 100],\n",
    "                     'max_depth' : [3, 5],\n",
    "                     'min_samples_split': [2],\n",
    "                     'learning_rate': [0.001, 0.1], \n",
    "                     'subsample': [0.5]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [10, 100], 'min_samples_split': [2], 'learning_rate': [0.001, 0.1], 'max_depth': [3, 5], 'subsample': [0.5]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(ensemble.GradientBoostingClassifier(), tuned_parameters, cv=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "()\n",
      "{'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.654 (+/-0.005) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.654 (+/-0.005) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.654 (+/-0.005) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.001, 'max_depth': 5, 'subsample': 0.5}\n",
      "0.654 (+/-0.005) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.001, 'max_depth': 5, 'subsample': 0.5}\n",
      "0.957 (+/-0.033) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.967 (+/-0.008) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3, 'subsample': 0.5}\n",
      "0.957 (+/-0.040) for {'min_samples_split': 2, 'n_estimators': 10, 'learning_rate': 0.1, 'max_depth': 5, 'subsample': 0.5}\n",
      "0.967 (+/-0.042) for {'min_samples_split': 2, 'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 5, 'subsample': 0.5}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.97      0.97       138\n",
      "        1.0       0.94      0.94      0.94        72\n",
      "\n",
      "avg / total       0.96      0.96      0.96       210\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SVC(C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.96      0.96       138\n",
      "        1.0       0.92      0.94      0.93        72\n",
      "\n",
      "avg / total       0.95      0.95      0.95       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf', 'linear'],\n",
    "                     'C': [1, 10, 1000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'kernel': ['rbf', 'linear'], 'C': [1, 10, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "()\n",
      "{'kernel': 'rbf', 'C': 1}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.978 (+/-0.035) for {'kernel': 'rbf', 'C': 1}\n",
      "0.978 (+/-0.020) for {'kernel': 'linear', 'C': 1}\n",
      "0.965 (+/-0.030) for {'kernel': 'rbf', 'C': 10}\n",
      "0.973 (+/-0.016) for {'kernel': 'linear', 'C': 10}\n",
      "0.947 (+/-0.047) for {'kernel': 'rbf', 'C': 1000}\n",
      "0.973 (+/-0.016) for {'kernel': 'linear', 'C': 1000}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.96      0.96       138\n",
      "        1.0       0.92      0.94      0.93        72\n",
      "\n",
      "avg / total       0.95      0.95      0.95       210\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

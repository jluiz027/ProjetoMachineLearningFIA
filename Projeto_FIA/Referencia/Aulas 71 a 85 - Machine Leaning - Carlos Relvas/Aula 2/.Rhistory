}
df = do.call(rbind, dfs)
plot(df[,1], df[,2], col=df[,3], pch=16,
xlab='X', ylab='Y', main='Clustering')
library(mixtools)
ellipse_bvn <- function(bvn, alpha, cor){
Xbar <- apply(bvn,2,mean)
S <- cov(bvn)
ellipse(Xbar, S, alpha = alpha, col=cor)
}
for(i in unique(df[,4])){
aux <- df[df[,4]==i,]
plot(aux[,1], aux[,2], col=aux[,3], pch=16,
xlab='X', ylab='Y', main=paste0('Idade: ', i),
xlim=c(25,40), ylim=c(29,36))
ellipse_bvn(aux[1:50,c(1,2)], 0.2, "black")
ellipse_bvn(aux[51:100,c(1,2)], 0.2, "red")
}
library(MASS)
idade = sort(rep(seq(30,65,by=5), 100))
betas1 = c(0.2, 0.05)
betas2 = c(0.05, -0.05)
dfs = list()
cont <- 1
for(i in unique(idade)){
dfs[[cont]] = cbind(mvrnorm(50,
c(23+betas1[1]*i, 30+betas1[2]*i),
matrix(c(1,0,0,1), nrow = 2)), 1, i)
cont<-cont+1
dfs[[cont]] = cbind(mvrnorm(50,
c(30+betas2[1]*i, 35+betas2[2]*i),
matrix(c(1,0,0,1), nrow = 2)), 2, i)
cont<-cont+1
}
df = do.call(rbind, dfs)
plot(df[,1], df[,2], col=df[,3], pch=16,
xlab='X', ylab='Y', main='Clustering')
install.packages("keras")
library(keras)
library(tseries)
install.packages("tseries")
csv
df = read.csv("/Users/carlos/Downloads/international-airline-passengers.csv")
head(df)
df = read.csv("/Users/carlos/Downloads/international-airline-passengers.csv",
header = F)
head(df)
df = read.csv("/Users/carlos/Downloads/international-airline-passengers.csv",
header = T)
plot.ts(df[,2])
scaled.ts <- scale(df[,2])
scaled.ts
scaled.ts <- scale(df[,2])[,1]
scaled.ts
scaled.ts <- scale(df[,2])[,1][-nrow(df)]
scaled.ts
library(caret)
preObj <- preProcess(df[, 2], method=c("center", "scale"))
preObj <- preProcess(data.frame(df[, 2]), method=c("center", "scale"))
newData <- predict(preObj, data.frame(df[, 2]))
newData
standardScaler <- preProcess(data.frame(df[, 2]), method=c("center", "scale"))
ts <- predict(standardScaler, data.frame(df[, 2]))
train_size = int(length(ts[,1]) * 0.67)
train_size = length(ts[,1]) * 0.67
train_size
train_size = round(length(ts[,1]) * 0.67,0)
train_size
train_size = round(length(ts[,1]) * 0.67,0)
train = ts[1:train_size,1],
test = ts[(train_size+1):nrow(ts),1]
print(len(train), len(test))
train = ts[1:train_size,1]
test = ts[(train_size+1):nrow(ts),1]
y_train = train[2:length(train)]
x_train = train[1:(length(train)-1)]
y_test = test[2:length(test)]
x_test = test[1:(length(test)-1)]
x_train <- array_reshape(x_train, c(length(x_train), 1, 1))
x_train
x_test <- array_reshape(x_test, c(length(x_test), 1, 1))
x_test
model <- keras_model_sequential()
install_keras()
install_keras()
install_keras()
model <- keras_model_sequential()
help(install_keras)
install_keras(method = "conda")
use_condaenv("r-tensorflow")
install_keras()
model <- keras_model_sequential()
1 - pchisq(10, 1)
1 - pchisq(10, 10)
1 - pchisq(10, 16)
1 - pchisq(20, 16)
setwd("/Users/carlos/Desktop/TextMining/")
install.packages('twitteR', dependencies=TRUE, repos='http://cran.rstudio.com/')
install.packages('plyr', dependencies=TRUE, repos='http://cran.rstudio.com/')
install.packages('stringr', dependencies=TRUE, repos='http://cran.rstudio.com/')
install.packages('ggplot2', dependencies=TRUE, repos='http://cran.rstudio.com/')
install.packages('RTextTools', dependencies=TRUE, repos='http://cran.rstudio.com/')
install.packages('e1071', dependencies=TRUE, repos='http://cran.rstudio.com/')
install.packages('dplyr', dependencies=TRUE, repos='http://cran.rstudio.com/')
install.packages('party', dependencies=TRUE, repos='http://cran.rstudio.com/')
library(twitteR)
library(plyr)
library(dplyr)
library(stringr)
library(ggplot2)
library(e1071)
library(RTextTools)
library(party)
df <- read.csv("twitter_samsung.csv", header=T, stringsAsFactors = F)
score.sentiment <- function(sentences, pos.words, neg.words){
scores <- laply(sentences, function(sentence, pos.words, neg.words){
sentence <- gsub('[[:punct:]]', "", sentence)
sentence <- gsub('[[:cntrl:]]', "", sentence)
sentence <- gsub('\\d+', "", sentence)
sentence <- str_replace_all(sentence, "[^[:alnum:]]", " ")
sentence <- tolower(sentence)
word.list <- str_split(sentence, '\\s+')
words <- unlist(word.list)
pos.matches <- match(words, pos.words)
neg.matches <- match(words, neg.words)
pos.matches <- !is.na(pos.matches)
neg.matches <- !is.na(neg.matches)
score <- sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words)
scores.df <- data.frame(score=scores, text=sentences)
return(scores.df)
}
pos <- scan('positive_words.txt', what='character', comment.char=';')
neg <- scan('negative_words.txt', what='character', comment.char=';')
pos.words <- c(pos, 'upgrade')
neg.words <- c(neg, 'wtf', 'wait', 'waiting', 'epicfail')
Dataset <- df
Dataset$text <- as.factor(Dataset$text)
scores <- score.sentiment(Dataset$text, pos.words, neg.words)
stat <- scores
stat$created <- df$created
stat$created <- as.Date(stat$created)
stat <- mutate(stat, tweet=ifelse(stat$score > 0, 'positive',
ifelse(stat$score < 0, 'negative', 'neutral')))
by.tweet <- group_by(stat, tweet, created)
by.tweet <- summarise(by.tweet, number=n())
ggplot(by.tweet, aes(created, number)) + geom_line(aes(group=tweet, color=tweet), size=2) +
geom_point(aes(group=tweet, color=tweet), size=4) +
theme(text = element_text(size=18), axis.text.x = element_text(angle=90, vjust=1)) +
ggtitle('Samsung')
id_notneutral <- stat[,4] %in% c('positive', 'negative')
data_model <- stat[id_notneutral,]
sentence <- data_model[,2]
sentence <- gsub('[[:punct:]]', "", sentence)
sentence <- gsub('[[:cntrl:]]', "", sentence)
sentence <- gsub('\\d+', "", sentence)
sentence <- str_replace_all(sentence, "[^[:alnum:]]", " ")
sentence <- tolower(sentence)
set.seed(42)
id_train <- sample(1:nrow(data_model), 0.8*nrow(data_model), replace = F)
mat= create_matrix(sentence, language="english",
removeStopwords=TRUE, removeNumbers=TRUE,
stemWords=FALSE)
help(create_matrix)
mat = as.matrix(mat)
classifier = naiveBayes(mat[id_train,], as.factor(data_model[id_train,4]))
predicted = predict(classifier, mat)
table(data_model[id_train,4], predicted[id_train])
table(data_model[-id_train,4], predicted[-id_train])
dados <- data.frame(cbind(data_model[,4], as.matrix(mat)))
names(dados)[1] <- c('Sentimento')
fit3 <- ctree(as.factor(Sentimento) ~ ., data=dados[id_train,],
controls = ctree_control(maxdepth = 3))
fit5 <- ctree(as.factor(Sentimento) ~ ., data=dados[id_train,],
controls = ctree_control(maxdepth = 5))
fit10 <- ctree(as.factor(Sentimento) ~ ., data=dados[id_train,],
controls = ctree_control(maxdepth = 10))
fit <- ctree(as.factor(Sentimento) ~ ., data=dados[id_train,])
predicted3 = predict(fit3, newdata=dados)
predicted5 = predict(fit5, newdata=dados)
predicted10 = predict(fit10, newdata=dados)
predicted = predict(fit, newdata=dados)
tab3 <- table(dados[-id_train,1], predicted3[-id_train])
(tab3[1,1]+tab3[2,2])/sum(tab3)
tab5 <- table(dados[-id_train,1], predicted5[-id_train])
(tab5[1,1]+tab5[2,2])/sum(tab5)
tab10 <- table(dados[-id_train,1], predicted10[-id_train])
(tab10[1,1]+tab10[2,2])/sum(tab10)
tab <- table(dados[-id_train,1], predicted[-id_train])
(tab[1,1]+tab[2,2])/sum(tab)
setwd("/Users/carlos/Desktop/Aula_ML_2018/Aula 5/")
dados_des <- read.csv("adult.data", header = F,
stringsAsFactors = F)
dados_test <- read.csv("adult.test", header = F,
stringsAsFactors = F)
nomes <- c("age", "workclass", "fnlwgt", "education",
"education_num", "marital_status", "occupation",
"relationship", "race", "sex", "capital_gain",
"capital_loss", "hours_per_week", "native_country",
"income")
names(dados_des) <- nomes
names(dados_test) <- nomes
vars_categ <- c("workclass", "education",
"marital_status", "occupation",
"relationship", "race", "sex", "native_country")
vars_cont <-  c("age", "education_num", "capital_gain",
"capital_loss", "hours_per_week")
formula <- paste0("as.factor(income) ~ ", paste0(vars_cont, collapse = "+"), "+",
paste0("as.factor(", vars_categ, ")", collapse = "+"))
fit <- glm(as.formula(formula), family="binomial", data=dados_des)
library(car)
vif(fit)
df <- read.table("train_titanic.csv",
stringsAsFactors = F,
header=T, sep=",")
set.seed(42)
id <- sample(1:nrow(df), 0.7*nrow(df))
df_train <- df[id,]
df_test <- df[-id,]
for(i in c('Parch','SibSp','Pclass')){
cat(paste0(i, "  : ",
sum(is.na(df_train[,i]))), "\n")
}
names(df)
for(i in c('Parch','SibSp','Pclass','Embarked')){
cat(paste0(i, "  : ",
sum(is.na(df_train[,i]))), "\n")
}
formula <- "as.factor(Survived) ~ Parch+
formula <- "as.factor(Survived) ~ Parch+
formula <- "as.factor(Survived) ~ Parch+
SibSp+Pclass+Embarked"
fit <- glm(as.formula(formula),
data = df_train,
family="binomial")
vif(fit)
names(fit)
fit$formula
strsplit(fit$formula," ~ ")
strsplit(as.character(fit$formula)," ~ ")
strsplit(as.character(fit$formula)," ~ ")[[3]]
strsplit(strsplit(as.character(fit$formula)," ~ ")[[3]]," + ")
strsplit(strsplit(as.character(fit$formula)," ~ ")[[3]],"+")
vars <- c("Parch","SibSp","Pclass","Embarked")
v=1
formula <- paste0("as.factor(Survived) ~ ", paste0(vars[-v], collapse = "+"))
formula
fit_aux <- glm(as.formula(formula),
data = df_train,
family="binomial")
anova(fit, fit_aux, test="LRT")
summary(fit)
a = anova(fit, fit_aux, test="LRT")
a$`Pr(>Chi)`
pvalues <- array()
vars <- c("Parch","SibSp","Pclass","Embarked")
for(v in 1:length(vars)){
formula <- paste0("as.factor(Survived) ~ ", paste0(vars[-v], collapse = "+"))
fit_aux <- glm(as.formula(formula),
data = df_train,
family="binomial")
pvalues[v]  <- anova(fit, fit_aux, test="LRT")$`Pr(>Chi)`
}
pvalues
anova(fit, fit_aux, test="LRT")$`Pr(>Chi)`
pvalues <- array()
vars <- c("Parch","SibSp","Pclass","Embarked")
for(v in 1:length(vars)){
formula <- paste0("as.factor(Survived) ~ ", paste0(vars[-v], collapse = "+"))
fit_aux <- glm(as.formula(formula),
data = df_train,
family="binomial")
pvalues[v]  <- anova(fit, fit_aux, test="LRT")$`Pr(>Chi)`[2]
}
pvalues
128*1.15
128*4.15
521*600
1350*0.2
521*870
soma <- sum(pvalues>0.05)
soma
pvalues
summary(fit)
vars[-which.max(pvalues)]
pvalues <- array()
vars_finais <- c("Parch","SibSp","Pclass","Embarked")
soma <- 1
while(soma > 0){
vars <- vars_finais
formula <- paste0("as.factor(Survived) ~ ", paste0(vars_finais, collapse = "+"))
fit <- glm(as.formula(formula),
data = df_train,
family="binomial")
for(v in 1:length(vars)){
formula <- paste0("as.factor(Survived) ~ ", paste0(vars[-v], collapse = "+"))
fit_aux <- glm(as.formula(formula),
data = df_train,
family="binomial")
pvalues[v]  <- anova(fit, fit_aux, test="LRT")$`Pr(>Chi)`[2]
}
soma <- sum(pvalues>0.05)
if(soma > 0) vars_finais <- vars[-which.max(pvalues)]
}
vars_finais
pvalues
soma
vars
vars_finais <- c("Parch","SibSp","Pclass","Embarked")
soma <- 1
while(soma > 0){
vars <- vars_finais
pvalues <- array()
formula <- paste0("as.factor(Survived) ~ ", paste0(vars_finais, collapse = "+"))
fit <- glm(as.formula(formula),
data = df_train,
family="binomial")
for(v in 1:length(vars)){
formula <- paste0("as.factor(Survived) ~ ", paste0(vars[-v], collapse = "+"))
fit_aux <- glm(as.formula(formula),
data = df_train,
family="binomial")
pvalues[v]  <- anova(fit, fit_aux, test="LRT")$`Pr(>Chi)`[2]
}
soma <- sum(pvalues>0.05)
if(soma > 0) vars_finais <- vars[-which.max(pvalues)]
}
vars_finais
vars
pvalues
all.vars(fir)
all.vars(fit)
all.vars(fit$formula)
all.vars(fit$formula)[-1]
help(grid.arrange)
library(gridExtra)
help(grid.arrange)
plot_def_count_time <- function(fit, dados.des, target, cohort=F){
listaVars <- all.vars(fit$formula)[-1]
for(i in 1:length(listaVars)){
def_rate <- tapply(dados.des[,target], dados.des[,listaVars[i]], mean)
group_size <- tapply(dados.des[,target], dados.des[,listaVars[i]], length)
total_month <- matrix(rep(apply(group_size, 2, sum), nrow(group_size)),
nrow=nrow(group_size), ncol=ncol(group_size), byrow = T)
group_size <- group_size/total_month
data_plot_def <- data.frame(Time = sort(rep(colnames(def_rate), nrow(def_rate))),
score_bins = rep(rownames(def_rate), ncol(def_rate)),
default = array(def_rate))
data_plot_len <- data.frame(Time = sort(rep(colnames(group_size), nrow(group_size))),
score_bins = rep(rownames(group_size), ncol(group_size)),
Size = array(group_size))
g1 <- ggplot(data=data_plot_def, aes(x=Time, y=default, group=score_bins, colour=score_bins)) +
geom_line(size=1.2) + geom_point(size=1.5, fill='white') + ggtitle('Default Rate by Score Bin')
g2 <- ggplot(data=data_plot_len, aes(x=Time, y=Size, group=score_bins, fill = score_bins)) +
geom_area() + ggtitle('Volume by Score Bin over time')
grid.arrange(g1,g2)
}
}
head(df_tr)
head(df_train)
dim(df_train)
plot_def_count_time(fit, df_train, "Survived", c(rep(1,310), rep(2,313)))
plot_def_count_time <- function(fit, dados.des, target, cohort){
listaVars <- all.vars(fit$formula)[-1]
for(i in 1:length(listaVars)){
def_rate <- tapply(dados.des[,target], list(dados.des[,listaVars[i]], cohort), mean)
group_size <- tapply(dados.des[,target], list(dados.des[,listaVars[i]], cohort), length)
total_month <- matrix(rep(apply(group_size, 2, sum), nrow(group_size)),
nrow=nrow(group_size), ncol=ncol(group_size), byrow = T)
group_size <- group_size/total_month
data_plot_def <- data.frame(Time = sort(rep(colnames(def_rate), nrow(def_rate))),
score_bins = rep(rownames(def_rate), ncol(def_rate)),
default = array(def_rate))
data_plot_len <- data.frame(Time = sort(rep(colnames(group_size), nrow(group_size))),
score_bins = rep(rownames(group_size), ncol(group_size)),
Size = array(group_size))
g1 <- ggplot(data=data_plot_def, aes(x=Time, y=default, group=score_bins, colour=score_bins)) +
geom_line(size=1.2) + geom_point(size=1.5, fill='white') + ggtitle('Default Rate by Score Bin')
g2 <- ggplot(data=data_plot_len, aes(x=Time, y=Size, group=score_bins, fill = score_bins)) +
geom_area() + ggtitle('Volume by Score Bin over time')
grid.arrange(g1,g2)
}
}
plot_def_count_time(fit, df_train, "Survived", c(rep(1,310), rep(2,313)))
dados.des = df_train
target = "Survived"
cohort = c(rep(1,310), rep(2,313))
listaVars <- all.vars(fit$formula)[-1]
listaVars
i=1
def_rate <- tapply(dados.des[,target], list(dados.des[,listaVars[i]], cohort), mean)
group_size <- tapply(dados.des[,target], list(dados.des[,listaVars[i]], cohort), length)
total_month <- matrix(rep(apply(group_size, 2, sum), nrow(group_size)),
nrow=nrow(group_size), ncol=ncol(group_size), byrow = T)
group_size <- group_size/total_month
group_size
def_rate
i=3
def_rate <- tapply(dados.des[,target], list(dados.des[,listaVars[i]], cohort), mean)
group_size <- tapply(dados.des[,target], list(dados.des[,listaVars[i]], cohort), length)
total_month <- matrix(rep(apply(group_size, 2, sum), nrow(group_size)),
nrow=nrow(group_size), ncol=ncol(group_size), byrow = T)
group_size <- group_size/total_month
group_size
cohort
def_rate <- tapply(dados.des[,target], list(dados.des[,listaVars[i]], cohort), mean)
def_rate
group_size <- tapply(dados.des[,target], list(dados.des[,listaVars[i]], cohort), length)
total_month <- matrix(rep(apply(group_size, 2, sum), nrow(group_size)),
nrow=nrow(group_size), ncol=ncol(group_size), byrow = T)
total_month
group_size
total_month <- matrix(rep(apply(group_size, 2, sum, na.rm=T), nrow(group_size)),
nrow=nrow(group_size), ncol=ncol(group_size), byrow = T)
total_month
group_size <- group_size/total_month
group_size
data_plot_def <- data.frame(Time = sort(rep(colnames(def_rate), nrow(def_rate))),
score_bins = rep(rownames(def_rate), ncol(def_rate)),
default = array(def_rate))
data_plot_len <- data.frame(Time = sort(rep(colnames(group_size), nrow(group_size))),
score_bins = rep(rownames(group_size), ncol(group_size)),
Size = array(group_size))
g1 <- ggplot(data=data_plot_def, aes(x=Time, y=default, group=score_bins, colour=score_bins)) +
geom_line(size=1.2) + geom_point(size=1.5, fill='white') + ggtitle('Default Rate by Score Bin')
g2 <- ggplot(data=data_plot_len, aes(x=Time, y=Size, group=score_bins, fill = score_bins)) +
geom_area() + ggtitle('Volume by Score Bin over time')
grid.arrange(g1,g2)
def_rate <- tapply(dados.des[,target], dados.des[,listaVars[i]], mean)
group_size <- tapply(dados.des[,target], dados.des[,listaVars[i]], length)
def_rate
group_size
total_month <- matrix(rep(apply(group_size, 2, sum, na.rm=T), nrow(group_size)),
nrow=nrow(group_size), ncol=ncol(group_size), byrow = T)
total_month
group_size
total_month <- sum(group_size, na.rm=T)
total_month
group_size <- group_size/total_month
group_size
data_plot_def <- data.frame(score_bins = rep(rownames(def_rate), ncol(def_rate)),
default = array(def_rate))
rep(rownames(def_rate), ncol(def_rate))
def_rate
data.frame(def_rate)
d1 <- data.frame(def_rate)
d1[,'category'] <- rownames(d1)
d1
g1 <- ggplot(data=df, aes(x=category, y=def_rate) +
geom_bar(stat="identity", fill="steelblue")+
theme_minimal()
g1 <- ggplot(data=data_plot_def, aes(x=Time, y=default, group=score_bins, colour=score_bins)) +
geom_line(size=1.2) + geom_point(size=1.5, fill='white') + ggtitle('Default Rate by Score Bin')
g2 <- ggplot(data=data_plot_len, aes(x=Time, y=Size, group=score_bins, fill = score_bins)) +
geom_area() + ggtitle('Volume by Score Bin over time')
grid.arrange(g1,g2)
g1 <- ggplot(data=df, aes(x=category, y=def_rate) +
geom_bar(stat="identity", fill="steelblue")+
theme_minimal()
)
g1 <- ggplot(data=df, aes(x=category, y=def_rate)) +
geom_bar(stat="identity", fill="steelblue")+
theme_minimal()
g1
g1 <- ggplot(data=d1, aes(x=category, y=def_rate)) +
geom_bar(stat="identity", fill="steelblue")+
theme_minimal()
g1
plot_def_count <- function(fit, dados.des, target){
listaVars <- all.vars(fit$formula)[-1]
for(i in 1:length(listaVars)){
def_rate <- tapply(dados.des[,target], dados.des[,listaVars[i]], mean)
group_size <- tapply(dados.des[,target], dados.des[,listaVars[i]], length)
total_month <- sum(group_size, na.rm=T)
group_size <- group_size/total_month
d1 <- data.frame(def_rate)
d1[,'category'] <- rownames(d1)
d2 <- data.frame(group_size)
d2[,'category'] <- rownames(d2)
g1 <- ggplot(data=d1, aes(x=category, y=def_rate)) +
geom_bar(stat="identity", fill="steelblue")+
theme_minimal()+ggtitle(paste0('Default rate by ', listaVars[i]))
g2 <- ggplot(data=d2, aes(x=category, y=def_rate)) +
geom_bar(stat="identity", fill="steelblue")+
theme_minimal()+ggtitle(paste0('Size by ', listaVars[i]))
grid.arrange(g1,g2)
}
}
plot_def_count(fit, df_train, "Survived")
i=3
def_rate <- tapply(dados.des[,target], dados.des[,listaVars[i]], mean)
group_size <- tapply(dados.des[,target], dados.des[,listaVars[i]], length)
total_month <- sum(group_size, na.rm=T)
group_size <- group_size/total_month
d1 <- data.frame(def_rate)
d1[,'category'] <- rownames(d1)
d2 <- data.frame(group_size)
d2[,'category'] <- rownames(d2)
g1 <- ggplot(data=d1, aes(x=category, y=def_rate)) +
geom_bar(stat="identity", fill="steelblue")+
theme_minimal()+ggtitle(paste0('Default rate by ', listaVars[i]))
g2 <- ggplot(data=d2, aes(x=category, y=def_rate)) +
geom_bar(stat="identity", fill="steelblue")+
theme_minimal()+ggtitle(paste0('Size by ', listaVars[i]))
grid.arrange(g1,g2)
g1
g2
g2 <- ggplot(data=d2, aes(x=category, y=group_size)) +
geom_bar(stat="identity", fill="steelblue")+
theme_minimal()+ggtitle(paste0('Size by ', listaVars[i]))
g2

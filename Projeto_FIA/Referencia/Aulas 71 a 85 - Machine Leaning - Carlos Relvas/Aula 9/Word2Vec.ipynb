{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('/Users/carlos/Downloads/wiki.en.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'teache', 0.7893733382225037), (u'teacher,', 0.7844662070274353), (u'teachers', 0.7713974714279175), (u'teacherman', 0.7344009280204773), (u'teached', 0.7318561673164368), (u'teacher/pupil', 0.729202926158905), (u'teachers`', 0.7286232113838196), (u'schoolteacher', 0.7279092073440552), (u'teachera', 0.7274622917175293), (u'\\u2018teacher', 0.7261091470718384)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar('teacher'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'soccer/lacrosse', 0.7822386026382446), (u'occer', 0.7781806588172913), (u'soccer/softball', 0.7671366930007935), (u'lacrosse/soccer', 0.7663369178771973), (u'soccers', 0.7609419226646423), (u'soccer\\u2014', 0.7531135082244873), (u'football/soccer/lacrosse', 0.7432413101196289), (u'soccer,and', 0.7427438497543335), (u'msoccer', 0.7422813773155212), (u'soccer,', 0.7378698587417603)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar('soccer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'lunar', 0.7346395254135132), (u'moons', 0.7316275835037231), (u'lunarr', 0.6258058547973633), (u'phobos', 0.6219738721847534), (u'sun/moon', 0.6167811155319214), (u'moonlee', 0.6117098927497864), (u'uranus', 0.6112249493598938), (u'moonbyul', 0.6105742454528809), (u'moon,', 0.6081600189208984), (u'\\u2014lunar', 0.607763409614563)]\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar('moon'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6651899\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('soccer', 'baseball'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21370612\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('soccer', 'car'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens: 2519370\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for word in model.vocab:\n",
    "    words.append(word)\n",
    "\n",
    "# Printing out number of tokens available\n",
    "print(\"Number of Tokens: {}\".format(len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of a word vector: 300\n"
     ]
    }
   ],
   "source": [
    "# Printing out the dimension of a word vector \n",
    "print(\"Dimension of a word vector: {}\".format(\n",
    "    len(model[words[0]])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector components of a word: [-0.060585  -0.35465    0.091571   0.37924   -0.43332    0.33352\n",
      " -0.039997  -0.36795   -0.054958  -0.054794  -0.23318    0.26513\n",
      " -0.64387    0.25681   -0.24388   -0.17607   -0.034843   0.026851\n",
      "  0.06506    0.1481    -0.41027    0.13094   -0.34636    0.33094\n",
      " -0.31887   -0.0065675 -0.17026    0.015678   0.12418    0.086442\n",
      "  0.1091    -0.16714   -0.41878    0.24766   -0.049762  -0.35074\n",
      "  0.081695  -0.53918   -0.21191   -0.68771    0.27134    0.20855\n",
      " -0.0080212  0.23765    0.24037   -0.27663   -0.056412  -0.26021\n",
      " -0.27986   -0.2049    -0.47042    0.19775   -0.14586    0.41511\n",
      " -0.45645   -0.028102  -0.34122    0.073674   0.12847    0.62578\n",
      " -0.066765   0.24551    0.62374   -0.068045   0.10239   -0.16786\n",
      " -0.50368    0.033411  -0.089627  -0.25144    0.12825    0.049497\n",
      " -0.50959    0.17839   -0.12124    0.7831     0.11123    0.48259\n",
      "  0.048027  -0.25611   -0.0076265  0.24399   -0.16697    0.21499\n",
      " -0.255      0.12175    0.28555    0.8288     0.0078243 -0.044595\n",
      "  0.092967  -0.3476     0.053204   0.007213   0.34844    0.11116\n",
      " -0.19407    0.071499  -0.18282   -0.063114  -0.11796    0.097528\n",
      "  0.2387     0.099047   0.3458    -0.45997   -0.0067126  0.11593\n",
      " -0.25158   -0.026835  -0.011422   0.041651   0.15323   -0.015883\n",
      "  0.054789  -0.0076075  0.16093   -0.21829   -0.076341  -0.050785\n",
      "  0.12947    0.3895     0.013136   0.23719   -0.15791   -0.3625\n",
      " -0.23533    0.20808    0.14547   -0.17915    0.081307   0.23726\n",
      "  0.15133   -0.0038726  0.004462  -0.095102  -0.24557    0.026786\n",
      " -0.47585    0.082557  -0.15164    0.10222   -0.08797    0.16702\n",
      " -0.35805    0.16204   -0.11929    0.19047    0.030028  -0.12166\n",
      " -0.018852  -0.30484    0.001513   0.35319    0.028645  -0.072436\n",
      " -0.059624  -0.13861    0.64372   -0.44813   -0.011817  -0.050851\n",
      "  0.2808     0.31988    0.28101    0.0011476 -0.056125  -0.55292\n",
      "  0.31573    0.028123   0.058537  -0.13062   -0.23187   -0.62911\n",
      " -0.10625    0.71591    0.0011624  0.24329   -0.094376  -0.013643\n",
      " -0.046138  -0.30847    0.21358   -0.045424  -0.16534    0.26726\n",
      " -0.44026   -0.13514   -0.069107  -0.090593   0.11035   -0.68606\n",
      " -0.044169  -0.10238    0.0027354 -0.066736  -0.45653    0.011489\n",
      " -0.02043   -0.46008    0.32049   -0.019811   0.054639  -0.033315\n",
      " -0.15208   -0.08044   -0.014846  -0.42881    0.6406     0.3314\n",
      "  0.5578    -0.12338    0.083353  -0.43803    0.32991    0.18177\n",
      " -0.0035382  0.08485   -0.51929   -0.11037    0.1689     0.097313\n",
      " -0.21618    0.20824    0.61715    0.042571   0.22618    0.13541\n",
      " -0.18635   -0.34555    0.39035   -0.30517   -0.024544  -0.19723\n",
      " -0.32495   -0.064893  -0.20041    0.096487  -0.0035591 -0.11544\n",
      "  0.34187   -0.048127   0.16034    0.092311  -0.21293    0.09037\n",
      " -0.082936   0.28318    0.049518   0.032377   0.48923   -0.021446\n",
      " -0.021651   0.11432   -0.13815    0.044452   0.07165   -0.55926\n",
      "  0.059329  -0.35524   -0.30342    0.093492   0.24044   -0.61254\n",
      " -0.57062    0.0078987  0.27163    0.0050317  0.21185   -0.21726\n",
      " -0.51201   -0.54035   -0.2461    -0.57749   -0.24254   -0.1431\n",
      "  0.1612     0.28769   -0.37634    0.28083   -0.16967   -0.01006\n",
      " -0.24663    0.11659   -0.09261   -0.098972  -0.13516    0.13266\n",
      "  0.24889    0.080624  -0.16791   -0.2051     0.018024   0.14052\n",
      "  0.012188  -0.084261   0.092279  -0.1221     0.1629     0.096632 ]\n"
     ]
    }
   ],
   "source": [
    "# Print out the vector of a word \n",
    "print(\"Vector components of a word: {}\".format(\n",
    "    model[words[0]]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: cars, Similarity: 0.83\n",
      "Word: automobile, Similarity: 0.72\n",
      "Word: truck, Similarity: 0.71\n",
      "Word: motorcar, Similarity: 0.70\n",
      "Word: vehicle, Similarity: 0.70\n",
      "Word: driver, Similarity: 0.69\n",
      "Word: drivecar, Similarity: 0.69\n",
      "Word: minivan, Similarity: 0.67\n",
      "Word: roadster, Similarity: 0.67\n",
      "Word: racecars, Similarity: 0.67\n"
     ]
    }
   ],
   "source": [
    "find_similar_to = 'car'\n",
    "\n",
    "# Finding out similar words [default= top 10]\n",
    "for similar_word in model.similar_by_word(find_similar_to):\n",
    "    print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
    "        similar_word[0], similar_word[1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word : madrid , Similarity: 0.70\n",
      "Word : valencias , Similarity: 0.70\n"
     ]
    }
   ],
   "source": [
    "word_add = ['lisboa', 'spain']\n",
    "word_sub = ['portugal']\n",
    "\n",
    "# Word vector addition and subtraction \n",
    "for resultant_word in model.most_similar(\n",
    "    positive=word_add, negative=word_sub\n",
    ")[0:2]:\n",
    "    print(\"Word : {0} , Similarity: {1:.2f}\".format(\n",
    "        resultant_word[0], resultant_word[1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word : queen , Similarity: 0.66\n",
      "Word : princess , Similarity: 0.58\n"
     ]
    }
   ],
   "source": [
    "word_add = ['king', 'woman']\n",
    "word_sub = ['man']\n",
    "\n",
    "# Word vector addition and subtraction \n",
    "for resultant_word in model.most_similar(\n",
    "    positive=word_add, negative=word_sub\n",
    ")[0:2]:\n",
    "    print(\"Word : {0} , Similarity: {1:.2f}\".format(\n",
    "        resultant_word[0], resultant_word[1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word : basketball , Similarity: 0.61\n",
      "Word : basketball,volleyball , Similarity: 0.57\n"
     ]
    }
   ],
   "source": [
    "word_add = ['soccer', 'basket']\n",
    "word_sub = ['foot']\n",
    "\n",
    "# Word vector addition and subtraction \n",
    "for resultant_word in model.most_similar(\n",
    "    positive=word_add, negative=word_sub\n",
    ")[0:2]:\n",
    "    print(\"Word : {0} , Similarity: {1:.2f}\".format(\n",
    "        resultant_word[0], resultant_word[1]\n",
    "    )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word : _corinthians , Similarity: 0.61\n",
      "Word : argentinos , Similarity: 0.59\n"
     ]
    }
   ],
   "source": [
    "word_add = ['corinthians', 'argentina']\n",
    "word_sub = ['brazil']\n",
    "\n",
    "# Word vector addition and subtraction \n",
    "for resultant_word in model.most_similar(\n",
    "    positive=word_add, negative=word_sub\n",
    ")[0:2]:\n",
    "    print(\"Word : {0} , Similarity: {1:.2f}\".format(\n",
    "        resultant_word[0], resultant_word[1]\n",
    "    )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_table(\"r8-train-no-stop.txt\", header=None)\n",
    "df_test = pd.read_table(\"r8-test-no-stop.txt\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>earn</td>\n",
       "      <td>champion products approves stock split champio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acq</td>\n",
       "      <td>computer terminal systems cpml completes sale ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>earn</td>\n",
       "      <td>cobanco inc cbco year net shr cts dlrs net ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>earn</td>\n",
       "      <td>international inc qtr jan oper shr loss two ct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>earn</td>\n",
       "      <td>brown forman inc bfd qtr net shr dlr cts net m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0  earn  champion products approves stock split champio...\n",
       "1   acq  computer terminal systems cpml completes sale ...\n",
       "2  earn  cobanco inc cbco year net shr cts dlrs net ass...\n",
       "3  earn  international inc qtr jan oper shr loss two ct...\n",
       "4  earn  brown forman inc bfd qtr net shr dlr cts net m..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = ['tag','text']\n",
    "df_test.columns = ['tag','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "earn        2840\n",
       "acq         1596\n",
       "crude        253\n",
       "trade        251\n",
       "money-fx     206\n",
       "interest     190\n",
       "ship         108\n",
       "grain         41\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = 300\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = MeanEmbeddingVectorizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vector.transform(df_train['text'])\n",
    "X_test = vector.transform(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5485, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2189, 300)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.fit_transform(df_train.tag)\n",
    "y_test = le.transform(df_test.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, ..., 2, 5, 6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    earn\n",
       "1     acq\n",
       "2    earn\n",
       "3    earn\n",
       "4    earn\n",
       "Name: tag, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 1596]\n",
      " [   1  253]\n",
      " [   2 2840]\n",
      " [   3   41]\n",
      " [   4  190]\n",
      " [   5  206]\n",
      " [   6  108]\n",
      " [   7  251]]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=42, max_depth=5, max_features=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features=50, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 6, ..., 1, 0, 6])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47042564, 0.0745147 , 0.16896657, ..., 0.05537622, 0.04395853,\n",
       "        0.11829636],\n",
       "       [0.50214184, 0.06230765, 0.15607123, ..., 0.06882188, 0.03916819,\n",
       "        0.09554233],\n",
       "       [0.50029993, 0.06113978, 0.18095292, ..., 0.04716504, 0.0490441 ,\n",
       "        0.09404471],\n",
       "       ...,\n",
       "       [0.49630306, 0.08287628, 0.16770939, ..., 0.04952111, 0.04212372,\n",
       "        0.10405391],\n",
       "       [0.64714245, 0.03553916, 0.162905  , ..., 0.03385341, 0.03228149,\n",
       "        0.04100206],\n",
       "       [0.62490188, 0.03908512, 0.15539071, ..., 0.03728763, 0.03422943,\n",
       "        0.05339167]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.82      0.68       696\n",
      "          1       0.00      0.00      0.00       121\n",
      "          2       0.83      0.93      0.88      1083\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       1.00      0.04      0.07        81\n",
      "          5       1.00      0.03      0.07        87\n",
      "          6       0.00      0.00      0.00        36\n",
      "          7       0.00      0.00      0.00        75\n",
      "\n",
      "avg / total       0.67      0.72      0.66      2189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
